#include <algorithm>
#include <map>
#include "opencv2/core.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/ccalib/omnidir.hpp"
#include "opencv2/ccalib/multicalib_charuco.hpp"
#include "opencv2/viz.hpp"

using namespace std;
using namespace cv;

const char * usage =
"\n example command line for multi-camera calibration by using random pattern \n"
"   multi_cameras_calibration -nc 5 -pw 800 -ph 600 -ct 1 -fe 0 -nm 25 -v 0 multi_camera_omnidir.xml \n"
"\n"
" the file multi_camera_omnidir.xml is generated by imagelist_creator as \n"
" imagelist_creator multi_camera_omnidir.xml *.* \n"
" note the first filename in multi_camera_omnidir.xml is the pattern, the rest are photo names,\n"
" photo names should be in form of cameraIdx-timestamp.*, and cameraIdx starts from 0";

static void help()
{
    printf("\n This is a sample for multi-camera calibration, so far it only support random pattern,\n"
           "see randomPattern.hpp for detail. Pinhole and omnidirectional cameras are both supported, \n"
           "for omnidirectional camera, see omnidir.hpp for detail.\n"
           "Usage: mutiCamCalib \n"
           "    -nc <num_camera> # number of cameras \n"
           "    -pw <pattern_width> # physical width of random pattern \n"
           "    -ph <pattern_height> # physical height of random pattern \n"
           "    -ct <camera_type> # camera type, 0 for pinhole and 1 for omnidirectional \n"
           "    -fe # whether show feature extraction\n"
           "    -nm # number of minimal matches of an image \n"
		   "	-v # whether show verbose information \n"
           "    input_data # text file with pattern file names and a list of photo names, the file is generated by imagelist_creator \n");
    printf("\n %s", usage);
}


int main(int argc, char** argv)
{
    int tileX = 7, tileY = 16;
    float squareWidth = 0.0f, tagWidth = 0.0f;
    int nCamera = 0, nMiniMatches = 0, cameraType = 0;
    const char* outputFilename = "multi-camera-results.xml";
    const char* inputFilename = 0;
    int showFeatureExtraction = 0, verbose = 0;
    if (argc < 2)
    {
        help();
        return 1;
    }

    for (int i = 1; i < argc; ++i)
    {
        const char* s = argv[i];
        if (strcmp( s, "-nc") == 0)
        {
            if (sscanf( argv[++i], "%u", &nCamera) != 1 || nCamera <= 0)
            {
                return fprintf(stderr, "Invalid number of cameras \n"), -1;
            }
        }
        else if ( strcmp( s, "-x" ) == 0 )
        {
            if (sscanf( argv[++i], "%u", &tileX) != 1 || tileX <=0 )
            {
                return fprintf(stderr, "Invalid number of tiles on X \n"), -1;
            }
        }
        else if ( strcmp( s, "-y" ) == 0 )
        {
            if (sscanf( argv[++i], "%u", &tileY) != 1 || tileY <=0 )
            {
                return fprintf(stderr, "Invalid number of tiles on Y \n"), -1;
            }
        }        else if ( strcmp( s, "-sw" ) == 0 )
        {
            if (sscanf( argv[++i], "%f", &squareWidth) != 1 || squareWidth <=0 )
            {
                return fprintf(stderr, "Invalid pattern width \n"), -1;
            }
        }
        else if ( strcmp( s, "-tw" ) == 0 )
        {
            if (sscanf( argv[++i], "%f", &tagWidth) != 1 || tagWidth <=0 )
            {
                return fprintf(stderr, "Invalid tag width \n"), -1;
            }
        }
        else if ( strcmp( s, "-ct" ) == 0 )
        {
            if (sscanf( argv[++i], "%u", &cameraType) != 1 || (cameraType !=0 && cameraType !=1 && cameraType !=2) )
            {
                return fprintf(stderr, "Invalid camera type, 0 for pinhole and 1 for omnidirectional \n"), -1;
            }
        }
        else if ( strcmp( s, "-fe" ) == 0 )
        {
            if (sscanf( argv[++i], "%u", &showFeatureExtraction) != 1 || (showFeatureExtraction !=1 && showFeatureExtraction !=0) )
            {
                return fprintf(stderr, "Not bool value, set to 0 or 1 \n"), -1;
            }
        }
        else if ( strcmp( s, "-nm" ) == 0 )
        {
            if (sscanf( argv[++i], "%u", &nMiniMatches) != 1 || nMiniMatches <=0 )
            {
                return fprintf(stderr, "Invalid number of minimal matches \n"), -1;
            }
        }
		else if ( strcmp( s, "-v" ) == 0 )
		{
			if (sscanf( argv[++i], "%u", &verbose) != 1 || (verbose !=1 && verbose !=0) )
			{
				return fprintf(stderr, "verbose is not bool value, set to 0 or 1 \n"), -1;
			}
		}
        else if( s[0] != '-')
        {
            inputFilename = s;
        }
        else
        {
            return fprintf( stderr, "Unknown option %s\n", s ), -1;
        }
    }

    // do multi-camera calibration
    multicalib::MultiCameraCalibrationCharuco multiCalib(cameraType, nCamera, inputFilename, tileX, tileY, squareWidth, tagWidth, aruco::PredefinedDictionaryType::DICT_6X6_250, verbose, showFeatureExtraction);

    multiCalib.loadImages();
    std::cout << "Done loading images" << std::endl;
    multiCalib.initialize();
    std::cout << "Done initializing" << std::endl;
    multiCalib.optimizeExtrinsics();
    std::cout << "Done optimizing extrinsics" << std::endl;

    // Rectification
    // Create rectification maps for every pair
    std::vector<Mat> cameraMatrices = multiCalib.getCameraMatrices();
    std::vector<Mat> cameraDistortions = multiCalib.getCameraDistortions();
    std::vector<Mat> cameraXis = multiCalib.getCameraXi();
    std::vector<multicalib::MultiCameraCalibrationCharuco::vertex> cameraPoses = multiCalib.getCameraPoses();

    typedef struct {
        Mat map_i_x;
        Mat map_i_y;
        Mat map_j_x;
        Mat map_j_y;
    } StereoMaps;

    std::map<std::pair<int, int>, StereoMaps> allStereoMapsMap;

    for (int i = 0; i < nCamera - 1; i++)
    {
        for (int j = i + 1; j < nCamera; j++)
        {
            Mat K_i = cameraMatrices[i];
            Mat K_j = cameraMatrices[j];

            Mat D_i = cameraDistortions[i];
            Mat D_j = cameraDistortions[j];

            Mat Xi_i = cameraXis[i];
            Mat Xi_j = cameraXis[j];

            Mat cam_pose_i = cameraPoses[i].pose;
            Mat cam_pose_j = cameraPoses[j].pose;

            Mat R_i, R_j, R, T;
            Mat cam_pose_i_j = cam_pose_j * cam_pose_i.inv();
            R = cam_pose_i_j({Range(0,3), Range(0,3)}).clone();
            T = cam_pose_i_j({Range(0,3), Range(3,4)}).clone();
            omnidir::stereoRectify(R, T, R_i, R_j);

            std::cout << i << " , " << j << std::endl;
            std::cout << R_i << std::endl;
            std::cout << R_j << std::endl;

            StereoMaps maps;
            auto pairKey = std::pair<int, int>(i, j);
            Mat Knew = Mat::eye(3, 3, CV_64FC1);
            Knew.at<double>(0,0) = 3840 / 3.145;
            Knew.at<double>(1,1) = 2160 / 3.145;

            omnidir::initUndistortRectifyMap(K_i, D_i, Xi_i, R_i, Knew, Size(3840, 2160), CV_32FC1, maps.map_i_x, maps.map_i_y, omnidir::RECTIFY_LONGLATI);
            omnidir::initUndistortRectifyMap(K_j, D_j, Xi_j, R_j, Knew, Size(3840, 2160), CV_32FC1, maps.map_j_x, maps.map_j_y, omnidir::RECTIFY_LONGLATI);
            auto ret = allStereoMapsMap.insert(std::pair<std::pair<int, int>, StereoMaps>{pairKey, maps});
        }
    }

    std::vector<std::vector<std::string>> fileList;
    for (int i = 0; i < nCamera; i++)
    {
        std::vector<std::string> tmpFileList;
        cv::glob(std::string(inputFilename) + "/*" + std::to_string(i) + "-*.png", tmpFileList, false);
        std::sort(tmpFileList.begin(), tmpFileList.end());
        fileList.push_back(tmpFileList);
    }

    int cam_1_index = 1;
    int cam_2_index = 2;
    // for (size_t i = 0; i < fileList[0].size(); i++)
    // {
    //     std::string imgPath_1 = fileList[cam_1_index][i];
    //     std::string imgPath_2 = fileList[cam_2_index][i];

    //     Mat img_1 = cv::imread(imgPath_1, IMREAD_GRAYSCALE);
    //     Mat img_2 = cv::imread(imgPath_2, IMREAD_GRAYSCALE);
    //     Mat resizedImage_1, resizedImage_2;
    //     Mat undistortedImage_1, resizedUndistortedImage_1;
    //     Mat undistortedImage_2, resizedUndistortedImage_2;
    //     StereoMaps currentMaps = allStereoMapsMap[std::pair<int, int>(cam_1_index, cam_2_index)];
    //     cv::remap(img_1, undistortedImage_1, currentMaps.map_i_x, currentMaps.map_i_y, cv::INTER_AREA);
    //     cv::remap(img_2, undistortedImage_2, currentMaps.map_j_x, currentMaps.map_j_y, cv::INTER_AREA);

    //     cv::resize(img_1, resizedImage_1, Size(img_1.cols / 4, img_1.rows / 4));
    //     cv::resize(img_2, resizedImage_2, Size(img_2.cols / 4, img_2.rows / 4));
    //     cv::resize(undistortedImage_1, resizedUndistortedImage_1, Size(undistortedImage_1.cols / 4, undistortedImage_1.rows / 4));
    //     cv::resize(undistortedImage_2, resizedUndistortedImage_2, Size(undistortedImage_1.cols / 4, undistortedImage_1.rows / 4));
    //     cv::imshow("Raw 1", resizedImage_1);
    //     cv::imshow("Undistorted 1", resizedUndistortedImage_1);
    //     cv::imshow("Raw 2", resizedImage_2);
    //     cv::imshow("Undistorted 2", resizedUndistortedImage_2);
    //     cv::waitKey(0);
    // }

    for (size_t i = 0; i < fileList[0].size(); i++)
    {
        std::string imgPath_1 = fileList[cam_1_index][i];
        std::string imgPath_2 = fileList[cam_2_index][i];

        Mat img_1 = cv::imread(imgPath_1, IMREAD_GRAYSCALE);
        Mat img_2 = cv::imread(imgPath_2, IMREAD_GRAYSCALE);
        Mat rectified_img_1, rectified_img_2;

        Mat Knew = Mat::eye(3, 3, CV_64FC1);
        Knew.at<double>(0,0) = 3840 / 3.145;
        Knew.at<double>(1,1) = 2160 / 3.145;

        Mat R, T;
        Mat cam_pose_i_j = cameraPoses[cam_2_index].pose * cameraPoses[cam_1_index].pose.inv();
        R = cam_pose_i_j({Range(0,3), Range(0,3)}).clone();
        T = cam_pose_i_j({Range(0,3), Range(3,4)}).clone();
        int numDisparities = 16*5;
        int SADWindowSize = 5;
        Mat dispMap, dispMapResized, pointcloud;
        int pointType = omnidir::XYZ;

        omnidir::stereoReconstruct(img_1, img_2, cameraMatrices[cam_1_index], cameraDistortions[cam_1_index], cameraXis[cam_1_index], cameraMatrices[cam_2_index], cameraDistortions[cam_2_index], cameraXis[cam_2_index], R, T, omnidir::RECTIFY_LONGLATI, numDisparities, SADWindowSize, dispMap, rectified_img_1, rectified_img_2, Size(3840, 2160), Knew, pointcloud, pointType);

        resize(dispMap, dispMapResized, Size(dispMap.cols / 4, dispMap.rows / 4));
        dispMapResized.convertTo(dispMapResized, CV_8UC1);

        Mat rect_1_resized, rect_2_resized, both_rects;
        resize(rectified_img_1, rect_1_resized, Size(3840 / 4, 2160 / 4));
        resize(rectified_img_2, rect_2_resized, Size(3840 / 4, 2160 / 4));
        hconcat(rect_1_resized, rect_2_resized, both_rects);
        cvtColor(both_rects, both_rects, COLOR_GRAY2RGB);
        for (int k = 0; k < both_rects.rows; k += both_rects.rows / 20)
            line(both_rects, Point(0, k), Point(both_rects.cols, k), Scalar(0, 255, 0), 1);

        imshow("Rectied", both_rects);
        imshow("Disparity", dispMapResized);
        waitKey(0);
    }

	multiCalib.writeParameters(outputFilename);
}
